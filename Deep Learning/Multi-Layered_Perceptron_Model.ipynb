{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dnn1",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Jeuni/dubluve/blob/master/Multi-Layered_Perceptron_Model.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Jj81-vJbygt0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "9fb5179a-1cce-413e-bf1a-c676800de256"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmpagks366t/pubring.gpg' created\n",
            "gpg: /tmp/tmpagks366t/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x_oR8Fw8yrqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "dce8332e-0adf-41c4-b253-bdc3e6790180"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow-gpu\n",
        "!pip install pandas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.10.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.31.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: numpy<=1.14.5,>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.5)\n",
            "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (39.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.5.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.6.1)\n",
            "Requirement already satisfied: tensorboard<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow) (2.6.11)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow) (0.14.1)\n",
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c3/000755084b5e7b5a11df1b9166a54936075ec280b7a615cecce42973fc8b/tensorflow_gpu-1.10.1-cp36-cp36m-manylinux1_x86_64.whl (253.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 253.3MB 87kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x4f31c000 @  0x7f826f70e1c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.5.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (39.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.31.1)\n",
            "Requirement already satisfied: numpy<=1.14.5,>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.14.5)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.6.1)\n",
            "Requirement already satisfied: tensorboard<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow-gpu) (2.6.11)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow-gpu) (0.14.1)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.10.1\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.22.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.5)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nnqec9LQ36-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1837
        },
        "outputId": "c83b0874-a32d-4900-fae0-699f0b88dbfb"
      },
      "cell_type": "code",
      "source": [
        "# To determine which version you're using:\n",
        "!pip show tensorflow\n",
        "\n",
        "# For the current version: \n",
        "!pip install --upgrade tensorflow\n",
        "\n",
        "# For a specific version:\n",
        "!pip install tensorflow==1.2\n",
        "\n",
        "# For the latest nightly build:\n",
        "!pip install tf-nightly"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.10.1\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: opensource@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: astor, grpcio, protobuf, numpy, termcolor, wheel, gast, setuptools, tensorboard, absl-py, six\n",
            "Required-by: \n",
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (1.10.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.5.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.31.1)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.10.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.6.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<=1.14.5,>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.5)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (39.1.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow) (2.6.11)\n",
            "Collecting tensorflow==1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/55/7995cc1e9e60fa37ea90e6777d832e75026fde5c6109215d892aaff2e9b7/tensorflow-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (35.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 35.0MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (3.6.1)\n",
            "Collecting backports.weakref==1.0rc1 (from tensorflow==1.2)\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f7/ae34b6818b603e264f26fe7db2bd07850ce331ce2fde74b266d61f4a2d87/backports.weakref-1.0rc1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.14.5)\n",
            "Collecting html5lib==0.9999999 (from tensorflow==1.2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K    100% |████████████████████████████████| 890kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (0.14.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.11.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (0.31.1)\n",
            "Collecting bleach==1.5.0 (from tensorflow==1.2)\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Collecting markdown==2.2.0 (from tensorflow==1.2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/99/288a81a38526a42c98b5b9832c6e339ca8d5dd38b19a53abfac7c8037c7f/Markdown-2.2.0.tar.gz (236kB)\n",
            "\u001b[K    100% |████████████████████████████████| 245kB 25.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorflow==1.2) (39.1.0)\n",
            "Building wheels for collected packages: html5lib, markdown\n",
            "  Running setup.py bdist_wheel for html5lib ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "  Running setup.py bdist_wheel for markdown ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b6/52/17/f0af18e3e0ec6fa60b361ffed15b4c3468f6f3bcdb87fbe079\n",
            "Successfully built html5lib markdown\n",
            "\u001b[31mtensorboard 1.10.0 has requirement markdown>=2.6.8, but you'll have markdown 2.2.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: backports.weakref, html5lib, bleach, markdown, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 2.1.4\n",
            "    Uninstalling bleach-2.1.4:\n",
            "      Successfully uninstalled bleach-2.1.4\n",
            "  Found existing installation: Markdown 2.6.11\n",
            "    Uninstalling Markdown-2.6.11:\n",
            "      Successfully uninstalled Markdown-2.6.11\n",
            "  Found existing installation: tensorflow 1.10.1\n",
            "    Uninstalling tensorflow-1.10.1:\n",
            "      Successfully uninstalled tensorflow-1.10.1\n",
            "Successfully installed backports.weakref-1.0rc1 bleach-1.5.0 html5lib-0.9999999 markdown-2.2.0 tensorflow-1.2.0\n",
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/6a/e823f96343a7f84a4c7980eb18ed51be31615da00ef50f134882a7c7dbe8/tf_nightly-1.12.0.dev20180923-cp36-cp36m-manylinux1_x86_64.whl (63.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 63.7MB 647kB/s \n",
            "\u001b[?25hCollecting tb-nightly<1.12.0a0,>=1.11.0a0 (from tf-nightly)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/2d/8897dae532543293bee72cb785ee65d7e28350f89437c035de514b9469e0/tb_nightly-1.11.0a20180923-py3-none-any.whl (3.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 947kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.5.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (39.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.31.1)\n",
            "Collecting keras-applications>=1.0.5 (from tf-nightly)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/9c/6e9393ead970fd97be0cfde912697dafec5800d9191f5ba25352fa537d72/Keras_Applications-1.0.5-py2.py3-none-any.whl (44kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 19.6MB/s \n",
            "\u001b[?25hCollecting keras-preprocessing>=1.0.3 (from tf-nightly)\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/bd/796f986980da4d6adc77ffd8b2b11074e7b17a7b74b03789aefac5709c4b/Keras_Preprocessing-1.0.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.14.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.6.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.11.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.12.0a0,>=1.11.0a0->tf-nightly) (0.14.1)\n",
            "Collecting markdown>=2.6.8 (from tb-nightly<1.12.0a0,>=1.11.0a0->tf-nightly)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/fd/e22357c299e93c0bc11ec8ba54e79f98dd568e09adfe9b39d6852c744938/Markdown-3.0-py2.py3-none-any.whl (89kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 27.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.5->tf-nightly) (2.1.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.5->tf-nightly) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-preprocessing>=1.0.3->tf-nightly) (0.19.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.6->keras-applications>=1.0.5->tf-nightly) (3.13)\n",
            "\u001b[31mtensorflow 1.2.0 has requirement markdown==2.2.0, but you'll have markdown 3.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: markdown, tb-nightly, keras-applications, keras-preprocessing, tf-nightly\n",
            "  Found existing installation: Markdown 2.2.0\n",
            "    Uninstalling Markdown-2.2.0:\n",
            "      Successfully uninstalled Markdown-2.2.0\n",
            "Successfully installed keras-applications-1.0.5 keras-preprocessing-1.0.3 markdown-3.0 tb-nightly-1.11.0a20180923 tf-nightly-1.12.0.dev20180923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "00Vvk4JVWEEy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "f5e726d8-bc04-435a-ded8-b80966cb68d5"
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log’.\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lzVI9JGUyrm0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xqdq3HCkywf-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "c6fca8ea-fa0d-4134-bc38-5c1bcde6e780"
      },
      "cell_type": "code",
      "source": [
        "# Import datasets & set datasets\n",
        "\n",
        "X_data = list()\n",
        "Y_data = list()\n",
        "X_test = list()\n",
        "Y_test = list()\n",
        "\n",
        "def split(dataset, result, dx, dy):\n",
        "    for row in dataset:\n",
        "        rows = list()\n",
        "        for column in row:\n",
        "            rows.append(column.split())\n",
        "        rowdata = [list(map(int, i)) for i in rows]\n",
        "        dx.append(rowdata[0])\n",
        "        dy.append(result)\n",
        "\n",
        "\n",
        "def get(n_datasets, path, result, dx, dy):\n",
        "    filename = input('Please type the name of file : ')\n",
        "    for i in range(1, n_datasets):\n",
        "        name = path + filename + '/' + filename + str(i) + '.csv'\n",
        "        file = pd.read_csv(name)\n",
        "        dataset = file.values.tolist()\n",
        "        split(dataset, result, dx, dy)\n",
        "\n",
        "def load(x, y, result):\n",
        "  if str(result) == '[1, 0]':\n",
        "      path = 'gdrive/My Drive/datasets/'\n",
        "  else:\n",
        "      path = 'gdrive/My Drive/datasets/nobody/'\n",
        "  n_datasets = int(input('Please type the number of datasets : '))\n",
        "  get(n_datasets, path, result, x, y)\n",
        "  \n",
        "\n",
        "n = int(input(\"Please type the number of days: \"))\n",
        "for i in range(n):\n",
        "    load(X_data, Y_data, [1, 0])  # Exist\n",
        "load(X_data, Y_data, [0, 1])  # No Exist\n",
        "# Test Set\n",
        "load(X_test, Y_test, [1, 0]) \n",
        "load(X_test, Y_test, [0, 1])\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please type the number of days: 5\n",
            "Please type the number of datasets : 181\n",
            "Please type the name of file : labeled_data1_20180814_153212_human\n",
            "Please type the number of datasets : 127\n",
            "Please type the name of file : labeled_data1_20180813_164819_human\n",
            "Please type the number of datasets : 291\n",
            "Please type the name of file : labeled_data1_20180810_125246_human\n",
            "Please type the number of datasets : 156\n",
            "Please type the name of file : labeled_data1_20180810_092138_human\n",
            "Please type the number of datasets : 87\n",
            "Please type the name of file : labeled_data1_20180809_173925_human\n",
            "Please type the number of datasets : 59\n",
            "Please type the name of file : labeled_data1_20180814_102745_none\n",
            "Please type the number of datasets : 355\n",
            "Please type the name of file : labeled_data1_20180814_102745_human\n",
            "Please type the number of datasets : 18\n",
            "Please type the name of file : labeled_data3_20180814_153212_none\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7bg4AWwo_5kw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.02\n",
        "total_epochs = 500\n",
        "log_path='gdrive/My Drive/test_logs0923_dnn_rate002_layermod_e1000'\n",
        "save_path = 'gdrive/My Drive/model/dnn0923_rate002_layermod_e1000'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DSlNmpr972uE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "# Construct the model\n",
        "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
        "X = tf.placeholder(tf.float32, name='X')\n",
        "Y = tf.placeholder(tf.float32, name='Y')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QGnZTppx72mo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope('weight'):\n",
        "  W1 = tf.Variable(tf.random_uniform([100, 100], -1., 1.), name='W1')\n",
        "  W2 = tf.Variable(tf.random_uniform([100, 50], -1., 1.), name='W2')\n",
        "  W3 = tf.Variable(tf.random_uniform([50, 25], -1., 1.), name='W3')\n",
        "  W4 = tf.Variable(tf.random_uniform([25, 2], -1., 1.), name='W4')\n",
        "  b1 = tf.Variable(tf.zeros([100]), name='b1')\n",
        "  b2 = tf.Variable(tf.zeros([50]), name='b2')\n",
        "  b3 = tf.Variable(tf.zeros([25]), name='b3')\n",
        "  b4 = tf.Variable(tf.zeros([2]), name='b4')\n",
        "  \n",
        "  W_hist1 = tf.summary.histogram('Weight1', W1)\n",
        "  W_hist2 = tf.summary.histogram('Weight2', W1)  \n",
        "  W_hist3 = tf.summary.histogram('Weight3', W1)\n",
        "  W_hist4 = tf.summary.histogram('Weight4', W1)\n",
        "  b_hist1 = tf.summary.histogram('bias1', b1)\n",
        "  b_hist2 = tf.summary.histogram('bias2', b1)  \n",
        "  b_hist3 = tf.summary.histogram('bias3', b1)\n",
        "  b_hist4 = tf.summary.histogram('bias4', b1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uB5uQC8C72am",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope('layer1'):\n",
        "  L1 = tf.add(tf.matmul(X, W1), b1)\n",
        "  L1 = tf.nn.relu(L1)\n",
        "with tf.name_scope('layer2'):\n",
        "  L2 = tf.add(tf.matmul(L1, W2), b2)\n",
        "  L2 = tf.nn.relu(L2)\n",
        "with tf.name_scope('layer3'):\n",
        "  L3 = tf.add(tf.matmul(L2, W3), b3)\n",
        "  L3 = tf.nn.relu(L3)\n",
        "with tf.name_scope('layer4'):\n",
        "  model = tf.add(tf.matmul(L3, W4), b4, name='model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wpFb9kc48xpm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "ff58ffe3-130f-4322-856f-19730487a4cc"
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope('cost'):\n",
        "  # Cross-Entropy\n",
        "  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=model))\n",
        "  cost_summ = tf.summary.scalar('cost', cost)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-17-3f0b8b5d3038>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3bRutAcw8-F_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8923
        },
        "outputId": "c48d1d5c-e66e-4beb-aedc-b91e9757a48b"
      },
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(cost, global_step=global_step, name='op')\n",
        "\n",
        "with tf.name_scope('accuracy'):\n",
        "  is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "  tf.summary.scalar('accuracy', accuracy)\n",
        "\n",
        "with tf.Session() as sess:  \n",
        "  merged = tf.summary.merge_all()\n",
        "  writer = tf.summary.FileWriter(log_path, sess.graph)\n",
        "  sess = tf.Session()\n",
        "  saver = tf.train.Saver(tf.global_variables())\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  # make input and target to train\n",
        "  batch_xs = X_data\n",
        "  batch_ys = Y_data \n",
        "\n",
        "for step in range(total_epochs):\n",
        "  summary, _, loss =  sess.run([merged, train_op, cost], \n",
        "                      feed_dict={X: batch_xs, Y: batch_ys})\n",
        "  writer.add_summary(summary, step)\n",
        "  \n",
        "  print('Step: %d, ' % sess.run(global_step), \n",
        "        'Cost: %.3f' % sess.run(cost, feed_dict={X: X_data, Y: Y_data}))\n",
        "\n",
        "saver.save(sess, save_path, global_step=global_step)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step: 1,  Cost: 326618.906\n",
            "Step: 2,  Cost: 182144.938\n",
            "Step: 3,  Cost: 85614.859\n",
            "Step: 4,  Cost: 37781.051\n",
            "Step: 5,  Cost: 26800.996\n",
            "Step: 6,  Cost: 32245.660\n",
            "Step: 7,  Cost: 18815.539\n",
            "Step: 8,  Cost: 4764.039\n",
            "Step: 9,  Cost: 13053.898\n",
            "Step: 10,  Cost: 11220.648\n",
            "Step: 11,  Cost: 2702.407\n",
            "Step: 12,  Cost: 12992.347\n",
            "Step: 13,  Cost: 14131.169\n",
            "Step: 14,  Cost: 6122.830\n",
            "Step: 15,  Cost: 7030.607\n",
            "Step: 16,  Cost: 12129.751\n",
            "Step: 17,  Cost: 11026.570\n",
            "Step: 18,  Cost: 5012.800\n",
            "Step: 19,  Cost: 5122.964\n",
            "Step: 20,  Cost: 8577.138\n",
            "Step: 21,  Cost: 5041.815\n",
            "Step: 22,  Cost: 2948.223\n",
            "Step: 23,  Cost: 5258.666\n",
            "Step: 24,  Cost: 3463.521\n",
            "Step: 25,  Cost: 1495.036\n",
            "Step: 26,  Cost: 3109.349\n",
            "Step: 27,  Cost: 958.986\n",
            "Step: 28,  Cost: 3199.952\n",
            "Step: 29,  Cost: 3569.375\n",
            "Step: 30,  Cost: 1154.573\n",
            "Step: 31,  Cost: 3648.904\n",
            "Step: 32,  Cost: 4166.133\n",
            "Step: 33,  Cost: 1072.820\n",
            "Step: 34,  Cost: 3577.404\n",
            "Step: 35,  Cost: 4876.316\n",
            "Step: 36,  Cost: 3478.708\n",
            "Step: 37,  Cost: 650.805\n",
            "Step: 38,  Cost: 2659.602\n",
            "Step: 39,  Cost: 1717.818\n",
            "Step: 40,  Cost: 1581.164\n",
            "Step: 41,  Cost: 2235.699\n",
            "Step: 42,  Cost: 830.196\n",
            "Step: 43,  Cost: 2323.236\n",
            "Step: 44,  Cost: 2309.653\n",
            "Step: 45,  Cost: 539.525\n",
            "Step: 46,  Cost: 1515.833\n",
            "Step: 47,  Cost: 787.620\n",
            "Step: 48,  Cost: 1518.571\n",
            "Step: 49,  Cost: 1334.269\n",
            "Step: 50,  Cost: 848.622\n",
            "Step: 51,  Cost: 1152.973\n",
            "Step: 52,  Cost: 392.679\n",
            "Step: 53,  Cost: 695.527\n",
            "Step: 54,  Cost: 517.445\n",
            "Step: 55,  Cost: 399.777\n",
            "Step: 56,  Cost: 864.547\n",
            "Step: 57,  Cost: 349.319\n",
            "Step: 58,  Cost: 993.088\n",
            "Step: 59,  Cost: 396.764\n",
            "Step: 60,  Cost: 1369.696\n",
            "Step: 61,  Cost: 771.972\n",
            "Step: 62,  Cost: 1156.920\n",
            "Step: 63,  Cost: 1355.340\n",
            "Step: 64,  Cost: 312.637\n",
            "Step: 65,  Cost: 884.481\n",
            "Step: 66,  Cost: 363.604\n",
            "Step: 67,  Cost: 1081.813\n",
            "Step: 68,  Cost: 675.200\n",
            "Step: 69,  Cost: 1016.725\n",
            "Step: 70,  Cost: 932.270\n",
            "Step: 71,  Cost: 668.597\n",
            "Step: 72,  Cost: 749.007\n",
            "Step: 73,  Cost: 543.998\n",
            "Step: 74,  Cost: 570.009\n",
            "Step: 75,  Cost: 502.367\n",
            "Step: 76,  Cost: 324.164\n",
            "Step: 77,  Cost: 813.547\n",
            "Step: 78,  Cost: 473.943\n",
            "Step: 79,  Cost: 845.772\n",
            "Step: 80,  Cost: 679.512\n",
            "Step: 81,  Cost: 664.240\n",
            "Step: 82,  Cost: 667.258\n",
            "Step: 83,  Cost: 553.945\n",
            "Step: 84,  Cost: 462.454\n",
            "Step: 85,  Cost: 745.127\n",
            "Step: 86,  Cost: 547.407\n",
            "Step: 87,  Cost: 632.586\n",
            "Step: 88,  Cost: 483.856\n",
            "Step: 89,  Cost: 697.790\n",
            "Step: 90,  Cost: 605.672\n",
            "Step: 91,  Cost: 530.820\n",
            "Step: 92,  Cost: 426.142\n",
            "Step: 93,  Cost: 631.953\n",
            "Step: 94,  Cost: 537.821\n",
            "Step: 95,  Cost: 536.631\n",
            "Step: 96,  Cost: 418.751\n",
            "Step: 97,  Cost: 671.562\n",
            "Step: 98,  Cost: 548.784\n",
            "Step: 99,  Cost: 435.334\n",
            "Step: 100,  Cost: 335.100\n",
            "Step: 101,  Cost: 604.915\n",
            "Step: 102,  Cost: 492.892\n",
            "Step: 103,  Cost: 489.640\n",
            "Step: 104,  Cost: 328.867\n",
            "Step: 105,  Cost: 685.532\n",
            "Step: 106,  Cost: 541.799\n",
            "Step: 107,  Cost: 448.169\n",
            "Step: 108,  Cost: 340.558\n",
            "Step: 109,  Cost: 640.083\n",
            "Step: 110,  Cost: 412.436\n",
            "Step: 111,  Cost: 550.202\n",
            "Step: 112,  Cost: 370.537\n",
            "Step: 113,  Cost: 717.382\n",
            "Step: 114,  Cost: 569.853\n",
            "Step: 115,  Cost: 496.479\n",
            "Step: 116,  Cost: 468.563\n",
            "Step: 117,  Cost: 429.535\n",
            "Step: 118,  Cost: 482.349\n",
            "Step: 119,  Cost: 261.069\n",
            "Step: 120,  Cost: 223.266\n",
            "Step: 121,  Cost: 260.034\n",
            "Step: 122,  Cost: 224.257\n",
            "Step: 123,  Cost: 225.792\n",
            "Step: 124,  Cost: 192.578\n",
            "Step: 125,  Cost: 205.712\n",
            "Step: 126,  Cost: 177.682\n",
            "Step: 127,  Cost: 162.967\n",
            "Step: 128,  Cost: 167.649\n",
            "Step: 129,  Cost: 157.204\n",
            "Step: 130,  Cost: 163.288\n",
            "Step: 131,  Cost: 154.016\n",
            "Step: 132,  Cost: 158.647\n",
            "Step: 133,  Cost: 152.642\n",
            "Step: 134,  Cost: 155.035\n",
            "Step: 135,  Cost: 151.567\n",
            "Step: 136,  Cost: 151.019\n",
            "Step: 137,  Cost: 149.617\n",
            "Step: 138,  Cost: 147.116\n",
            "Step: 139,  Cost: 147.051\n",
            "Step: 140,  Cost: 143.725\n",
            "Step: 141,  Cost: 144.612\n",
            "Step: 142,  Cost: 141.353\n",
            "Step: 143,  Cost: 142.254\n",
            "Step: 144,  Cost: 139.210\n",
            "Step: 145,  Cost: 139.987\n",
            "Step: 146,  Cost: 137.089\n",
            "Step: 147,  Cost: 137.424\n",
            "Step: 148,  Cost: 134.905\n",
            "Step: 149,  Cost: 135.126\n",
            "Step: 150,  Cost: 132.929\n",
            "Step: 151,  Cost: 133.027\n",
            "Step: 152,  Cost: 131.212\n",
            "Step: 153,  Cost: 131.168\n",
            "Step: 154,  Cost: 129.544\n",
            "Step: 155,  Cost: 129.352\n",
            "Step: 156,  Cost: 127.852\n",
            "Step: 157,  Cost: 127.574\n",
            "Step: 158,  Cost: 126.230\n",
            "Step: 159,  Cost: 125.877\n",
            "Step: 160,  Cost: 124.728\n",
            "Step: 161,  Cost: 124.313\n",
            "Step: 162,  Cost: 123.291\n",
            "Step: 163,  Cost: 122.825\n",
            "Step: 164,  Cost: 121.885\n",
            "Step: 165,  Cost: 121.380\n",
            "Step: 166,  Cost: 120.514\n",
            "Step: 167,  Cost: 119.994\n",
            "Step: 168,  Cost: 119.204\n",
            "Step: 169,  Cost: 118.695\n",
            "Step: 170,  Cost: 117.939\n",
            "Step: 171,  Cost: 117.436\n",
            "Step: 172,  Cost: 116.727\n",
            "Step: 173,  Cost: 116.207\n",
            "Step: 174,  Cost: 115.531\n",
            "Step: 175,  Cost: 115.000\n",
            "Step: 176,  Cost: 114.359\n",
            "Step: 177,  Cost: 113.829\n",
            "Step: 178,  Cost: 113.219\n",
            "Step: 179,  Cost: 112.699\n",
            "Step: 180,  Cost: 112.106\n",
            "Step: 181,  Cost: 111.590\n",
            "Step: 182,  Cost: 111.022\n",
            "Step: 183,  Cost: 110.512\n",
            "Step: 184,  Cost: 109.958\n",
            "Step: 185,  Cost: 109.453\n",
            "Step: 186,  Cost: 108.910\n",
            "Step: 187,  Cost: 108.405\n",
            "Step: 188,  Cost: 107.878\n",
            "Step: 189,  Cost: 107.376\n",
            "Step: 190,  Cost: 106.862\n",
            "Step: 191,  Cost: 106.367\n",
            "Step: 192,  Cost: 105.864\n",
            "Step: 193,  Cost: 105.375\n",
            "Step: 194,  Cost: 104.882\n",
            "Step: 195,  Cost: 104.402\n",
            "Step: 196,  Cost: 103.916\n",
            "Step: 197,  Cost: 103.442\n",
            "Step: 198,  Cost: 102.965\n",
            "Step: 199,  Cost: 102.497\n",
            "Step: 200,  Cost: 102.028\n",
            "Step: 201,  Cost: 101.564\n",
            "Step: 202,  Cost: 101.104\n",
            "Step: 203,  Cost: 100.643\n",
            "Step: 204,  Cost: 100.190\n",
            "Step: 205,  Cost: 99.734\n",
            "Step: 206,  Cost: 99.285\n",
            "Step: 207,  Cost: 98.838\n",
            "Step: 208,  Cost: 98.394\n",
            "Step: 209,  Cost: 97.955\n",
            "Step: 210,  Cost: 97.516\n",
            "Step: 211,  Cost: 97.082\n",
            "Step: 212,  Cost: 96.650\n",
            "Step: 213,  Cost: 96.220\n",
            "Step: 214,  Cost: 95.795\n",
            "Step: 215,  Cost: 95.370\n",
            "Step: 216,  Cost: 94.949\n",
            "Step: 217,  Cost: 94.531\n",
            "Step: 218,  Cost: 94.114\n",
            "Step: 219,  Cost: 93.701\n",
            "Step: 220,  Cost: 93.289\n",
            "Step: 221,  Cost: 92.880\n",
            "Step: 222,  Cost: 92.473\n",
            "Step: 223,  Cost: 92.068\n",
            "Step: 224,  Cost: 91.666\n",
            "Step: 225,  Cost: 91.266\n",
            "Step: 226,  Cost: 90.868\n",
            "Step: 227,  Cost: 90.472\n",
            "Step: 228,  Cost: 90.078\n",
            "Step: 229,  Cost: 89.687\n",
            "Step: 230,  Cost: 89.298\n",
            "Step: 231,  Cost: 88.911\n",
            "Step: 232,  Cost: 88.526\n",
            "Step: 233,  Cost: 88.143\n",
            "Step: 234,  Cost: 87.762\n",
            "Step: 235,  Cost: 87.385\n",
            "Step: 236,  Cost: 87.010\n",
            "Step: 237,  Cost: 86.637\n",
            "Step: 238,  Cost: 86.265\n",
            "Step: 239,  Cost: 85.895\n",
            "Step: 240,  Cost: 85.527\n",
            "Step: 241,  Cost: 85.160\n",
            "Step: 242,  Cost: 84.797\n",
            "Step: 243,  Cost: 84.435\n",
            "Step: 244,  Cost: 84.076\n",
            "Step: 245,  Cost: 83.718\n",
            "Step: 246,  Cost: 83.363\n",
            "Step: 247,  Cost: 83.009\n",
            "Step: 248,  Cost: 82.657\n",
            "Step: 249,  Cost: 82.307\n",
            "Step: 250,  Cost: 81.959\n",
            "Step: 251,  Cost: 81.614\n",
            "Step: 252,  Cost: 81.272\n",
            "Step: 253,  Cost: 80.931\n",
            "Step: 254,  Cost: 80.593\n",
            "Step: 255,  Cost: 80.256\n",
            "Step: 256,  Cost: 79.922\n",
            "Step: 257,  Cost: 79.589\n",
            "Step: 258,  Cost: 79.258\n",
            "Step: 259,  Cost: 78.930\n",
            "Step: 260,  Cost: 78.603\n",
            "Step: 261,  Cost: 78.278\n",
            "Step: 262,  Cost: 77.955\n",
            "Step: 263,  Cost: 77.634\n",
            "Step: 264,  Cost: 77.315\n",
            "Step: 265,  Cost: 76.998\n",
            "Step: 266,  Cost: 76.681\n",
            "Step: 267,  Cost: 76.366\n",
            "Step: 268,  Cost: 76.053\n",
            "Step: 269,  Cost: 75.742\n",
            "Step: 270,  Cost: 75.433\n",
            "Step: 271,  Cost: 75.126\n",
            "Step: 272,  Cost: 74.820\n",
            "Step: 273,  Cost: 74.516\n",
            "Step: 274,  Cost: 74.215\n",
            "Step: 275,  Cost: 73.915\n",
            "Step: 276,  Cost: 73.617\n",
            "Step: 277,  Cost: 73.321\n",
            "Step: 278,  Cost: 73.026\n",
            "Step: 279,  Cost: 72.734\n",
            "Step: 280,  Cost: 72.442\n",
            "Step: 281,  Cost: 72.152\n",
            "Step: 282,  Cost: 71.863\n",
            "Step: 283,  Cost: 71.575\n",
            "Step: 284,  Cost: 71.289\n",
            "Step: 285,  Cost: 71.004\n",
            "Step: 286,  Cost: 70.721\n",
            "Step: 287,  Cost: 70.439\n",
            "Step: 288,  Cost: 70.159\n",
            "Step: 289,  Cost: 69.880\n",
            "Step: 290,  Cost: 69.603\n",
            "Step: 291,  Cost: 69.326\n",
            "Step: 292,  Cost: 69.052\n",
            "Step: 293,  Cost: 68.778\n",
            "Step: 294,  Cost: 68.507\n",
            "Step: 295,  Cost: 68.236\n",
            "Step: 296,  Cost: 67.967\n",
            "Step: 297,  Cost: 67.699\n",
            "Step: 298,  Cost: 67.432\n",
            "Step: 299,  Cost: 67.166\n",
            "Step: 300,  Cost: 66.902\n",
            "Step: 301,  Cost: 66.640\n",
            "Step: 302,  Cost: 66.379\n",
            "Step: 303,  Cost: 66.119\n",
            "Step: 304,  Cost: 65.861\n",
            "Step: 305,  Cost: 65.604\n",
            "Step: 306,  Cost: 65.348\n",
            "Step: 307,  Cost: 65.094\n",
            "Step: 308,  Cost: 64.840\n",
            "Step: 309,  Cost: 64.588\n",
            "Step: 310,  Cost: 64.337\n",
            "Step: 311,  Cost: 64.087\n",
            "Step: 312,  Cost: 63.838\n",
            "Step: 313,  Cost: 63.590\n",
            "Step: 314,  Cost: 63.343\n",
            "Step: 315,  Cost: 63.098\n",
            "Step: 316,  Cost: 62.853\n",
            "Step: 317,  Cost: 62.609\n",
            "Step: 318,  Cost: 62.367\n",
            "Step: 319,  Cost: 62.125\n",
            "Step: 320,  Cost: 61.885\n",
            "Step: 321,  Cost: 61.646\n",
            "Step: 322,  Cost: 61.408\n",
            "Step: 323,  Cost: 61.172\n",
            "Step: 324,  Cost: 60.937\n",
            "Step: 325,  Cost: 60.702\n",
            "Step: 326,  Cost: 60.469\n",
            "Step: 327,  Cost: 60.236\n",
            "Step: 328,  Cost: 60.005\n",
            "Step: 329,  Cost: 59.774\n",
            "Step: 330,  Cost: 59.545\n",
            "Step: 331,  Cost: 59.316\n",
            "Step: 332,  Cost: 59.088\n",
            "Step: 333,  Cost: 58.861\n",
            "Step: 334,  Cost: 58.635\n",
            "Step: 335,  Cost: 58.410\n",
            "Step: 336,  Cost: 58.186\n",
            "Step: 337,  Cost: 57.963\n",
            "Step: 338,  Cost: 57.741\n",
            "Step: 339,  Cost: 57.520\n",
            "Step: 340,  Cost: 57.300\n",
            "Step: 341,  Cost: 57.082\n",
            "Step: 342,  Cost: 56.864\n",
            "Step: 343,  Cost: 56.647\n",
            "Step: 344,  Cost: 56.431\n",
            "Step: 345,  Cost: 56.215\n",
            "Step: 346,  Cost: 56.001\n",
            "Step: 347,  Cost: 55.787\n",
            "Step: 348,  Cost: 55.574\n",
            "Step: 349,  Cost: 55.362\n",
            "Step: 350,  Cost: 55.151\n",
            "Step: 351,  Cost: 54.941\n",
            "Step: 352,  Cost: 54.732\n",
            "Step: 353,  Cost: 54.523\n",
            "Step: 354,  Cost: 54.315\n",
            "Step: 355,  Cost: 54.107\n",
            "Step: 356,  Cost: 53.900\n",
            "Step: 357,  Cost: 53.694\n",
            "Step: 358,  Cost: 53.489\n",
            "Step: 359,  Cost: 53.284\n",
            "Step: 360,  Cost: 53.080\n",
            "Step: 361,  Cost: 52.877\n",
            "Step: 362,  Cost: 52.674\n",
            "Step: 363,  Cost: 52.473\n",
            "Step: 364,  Cost: 52.273\n",
            "Step: 365,  Cost: 52.074\n",
            "Step: 366,  Cost: 51.876\n",
            "Step: 367,  Cost: 51.678\n",
            "Step: 368,  Cost: 51.482\n",
            "Step: 369,  Cost: 51.286\n",
            "Step: 370,  Cost: 51.091\n",
            "Step: 371,  Cost: 50.897\n",
            "Step: 372,  Cost: 50.705\n",
            "Step: 373,  Cost: 50.513\n",
            "Step: 374,  Cost: 50.323\n",
            "Step: 375,  Cost: 50.134\n",
            "Step: 376,  Cost: 49.948\n",
            "Step: 377,  Cost: 49.768\n",
            "Step: 378,  Cost: 49.621\n",
            "Step: 379,  Cost: 49.549\n",
            "Step: 380,  Cost: 49.956\n",
            "Step: 381,  Cost: 52.147\n",
            "Step: 382,  Cost: 144.000\n",
            "Step: 383,  Cost: 365.176\n",
            "Step: 384,  Cost: 167.155\n",
            "Step: 385,  Cost: 84.288\n",
            "Step: 386,  Cost: 299.872\n",
            "Step: 387,  Cost: 293.271\n",
            "Step: 388,  Cost: 88.151\n",
            "Step: 389,  Cost: 55.194\n",
            "Step: 390,  Cost: 189.653\n",
            "Step: 391,  Cost: 495.214\n",
            "Step: 392,  Cost: 57.657\n",
            "Step: 393,  Cost: 584.122\n",
            "Step: 394,  Cost: 125.956\n",
            "Step: 395,  Cost: 1126.903\n",
            "Step: 396,  Cost: 981.431\n",
            "Step: 397,  Cost: 311.547\n",
            "Step: 398,  Cost: 483.372\n",
            "Step: 399,  Cost: 181.138\n",
            "Step: 400,  Cost: 191.844\n",
            "Step: 401,  Cost: 416.445\n",
            "Step: 402,  Cost: 168.687\n",
            "Step: 403,  Cost: 741.276\n",
            "Step: 404,  Cost: 538.829\n",
            "Step: 405,  Cost: 498.721\n",
            "Step: 406,  Cost: 671.573\n",
            "Step: 407,  Cost: 79.064\n",
            "Step: 408,  Cost: 925.359\n",
            "Step: 409,  Cost: 880.460\n",
            "Step: 410,  Cost: 57.500\n",
            "Step: 411,  Cost: 782.850\n",
            "Step: 412,  Cost: 852.599\n",
            "Step: 413,  Cost: 293.242\n",
            "Step: 414,  Cost: 575.096\n",
            "Step: 415,  Cost: 738.944\n",
            "Step: 416,  Cost: 181.214\n",
            "Step: 417,  Cost: 882.323\n",
            "Step: 418,  Cost: 858.169\n",
            "Step: 419,  Cost: 141.873\n",
            "Step: 420,  Cost: 709.887\n",
            "Step: 421,  Cost: 660.768\n",
            "Step: 422,  Cost: 4879.660\n",
            "Step: 423,  Cost: 305.288\n",
            "Step: 424,  Cost: 93.660\n",
            "Step: 425,  Cost: 532.105\n",
            "Step: 426,  Cost: 792.658\n",
            "Step: 427,  Cost: 479.577\n",
            "Step: 428,  Cost: 426.016\n",
            "Step: 429,  Cost: 758.948\n",
            "Step: 430,  Cost: 496.666\n",
            "Step: 431,  Cost: 381.147\n",
            "Step: 432,  Cost: 848.209\n",
            "Step: 433,  Cost: 511.329\n",
            "Step: 434,  Cost: 288.742\n",
            "Step: 435,  Cost: 1031.118\n",
            "Step: 436,  Cost: 448.910\n",
            "Step: 437,  Cost: 226.574\n",
            "Step: 438,  Cost: 610.499\n",
            "Step: 439,  Cost: 727.869\n",
            "Step: 440,  Cost: 206.960\n",
            "Step: 441,  Cost: 311.516\n",
            "Step: 442,  Cost: 667.086\n",
            "Step: 443,  Cost: 260.193\n",
            "Step: 444,  Cost: 135.360\n",
            "Step: 445,  Cost: 178.848\n",
            "Step: 446,  Cost: 946.544\n",
            "Step: 447,  Cost: 284.104\n",
            "Step: 448,  Cost: 149.845\n",
            "Step: 449,  Cost: 144.833\n",
            "Step: 450,  Cost: 717.943\n",
            "Step: 451,  Cost: 261.845\n",
            "Step: 452,  Cost: 160.577\n",
            "Step: 453,  Cost: 109.436\n",
            "Step: 454,  Cost: 585.552\n",
            "Step: 455,  Cost: 250.116\n",
            "Step: 456,  Cost: 196.672\n",
            "Step: 457,  Cost: 127.836\n",
            "Step: 458,  Cost: 487.144\n",
            "Step: 459,  Cost: 96.479\n",
            "Step: 460,  Cost: 332.240\n",
            "Step: 461,  Cost: 451.666\n",
            "Step: 462,  Cost: 165.793\n",
            "Step: 463,  Cost: 633.577\n",
            "Step: 464,  Cost: 138.807\n",
            "Step: 465,  Cost: 1133.760\n",
            "Step: 466,  Cost: 959.727\n",
            "Step: 467,  Cost: 308.318\n",
            "Step: 468,  Cost: 518.730\n",
            "Step: 469,  Cost: 97.391\n",
            "Step: 470,  Cost: 321.993\n",
            "Step: 471,  Cost: 110.771\n",
            "Step: 472,  Cost: 351.533\n",
            "Step: 473,  Cost: 104.763\n",
            "Step: 474,  Cost: 181.937\n",
            "Step: 475,  Cost: 195.545\n",
            "Step: 476,  Cost: 107.619\n",
            "Step: 477,  Cost: 179.553\n",
            "Step: 478,  Cost: 85.360\n",
            "Step: 479,  Cost: 218.460\n",
            "Step: 480,  Cost: 95.694\n",
            "Step: 481,  Cost: 114.732\n",
            "Step: 482,  Cost: 80.778\n",
            "Step: 483,  Cost: 157.972\n",
            "Step: 484,  Cost: 172.059\n",
            "Step: 485,  Cost: 213.985\n",
            "Step: 486,  Cost: 79.233\n",
            "Step: 487,  Cost: 217.013\n",
            "Step: 488,  Cost: 54.408\n",
            "Step: 489,  Cost: 136.586\n",
            "Step: 490,  Cost: 77.858\n",
            "Step: 491,  Cost: 135.874\n",
            "Step: 492,  Cost: 46.576\n",
            "Step: 493,  Cost: 79.403\n",
            "Step: 494,  Cost: 51.794\n",
            "Step: 495,  Cost: 59.215\n",
            "Step: 496,  Cost: 68.039\n",
            "Step: 497,  Cost: 45.434\n",
            "Step: 498,  Cost: 64.836\n",
            "Step: 499,  Cost: 49.405\n",
            "Step: 500,  Cost: 49.038\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gdrive/My Drive/model/dnn0923_rate002_layermod_e1000-500'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "i0KPPLW1_Vqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0bf05514-a14c-44d3-a123-b2ed1c8c5a71"
      },
      "cell_type": "code",
      "source": [
        "prediction = tf.argmax(model, axis=1)\n",
        "target = tf.argmax(Y, axis=1)\n",
        "print('예측값: ', sess.run(prediction, feed_dict={X: X_data}))\n",
        "print('실제값: ', sess.run(target, feed_dict={Y: Y_data}))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측값:  [0 0 0 ... 1 1 1]\n",
            "실제값:  [0 0 0 ... 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TI_gla5U_1jM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f38b4f38-7094-428f-dc8a-26c99124ed67"
      },
      "cell_type": "code",
      "source": [
        "# Print the Accuracy\n",
        "\n",
        "is_correct = tf.equal(prediction, target)\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: X_test, Y: Y_test}))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도: 76.58\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
