{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Jeuni/dubluve/blob/master/RNN-modified.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Jj81-vJbygt0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2528
        },
        "outputId": "221381c0-2fbe-4007-bdb1-df8c1a3a726f"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 18408 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128ubuntu5) ...\n",
            "Selecting previously unselected package libapparmor1:amd64.\n",
            "Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n",
            "Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Selecting previously unselected package libdbus-1-3:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dbus.\n",
            "Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking dbus (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dirmngr.\n",
            "Preparing to unpack .../04-dirmngr_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Selecting previously unselected package distro-info-data.\n",
            "Preparing to unpack .../05-distro-info-data_0.36ubuntu0.2_all.deb ...\n",
            "Unpacking distro-info-data (0.36ubuntu0.2) ...\n",
            "Selecting previously unselected package libkmod2:amd64.\n",
            "Preparing to unpack .../06-libkmod2_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Selecting previously unselected package kmod.\n",
            "Preparing to unpack .../07-kmod_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking kmod (24-1ubuntu2) ...\n",
            "Selecting previously unselected package lsb-release.\n",
            "Preparing to unpack .../08-lsb-release_9.20160110ubuntu5_all.deb ...\n",
            "Unpacking lsb-release (9.20160110ubuntu5) ...\n",
            "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
            "Preparing to unpack .../09-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n",
            "Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
            "Preparing to unpack .../10-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package iso-codes.\n",
            "Preparing to unpack .../11-iso-codes_3.75-1_all.deb ...\n",
            "Unpacking iso-codes (3.75-1) ...\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "Preparing to unpack .../12-libdbus-glib-1-2_0.108-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Selecting previously unselected package python-apt-common.\n",
            "Preparing to unpack .../13-python-apt-common_1.4.0~beta3build2_all.deb ...\n",
            "Unpacking python-apt-common (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-apt.\n",
            "Preparing to unpack .../14-python3-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python3-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-dbus.\n",
            "Preparing to unpack .../15-python3-dbus_1.2.4-1build3_amd64.deb ...\n",
            "Unpacking python3-dbus (1.2.4-1build3) ...\n",
            "Selecting previously unselected package python3-gi.\n",
            "Preparing to unpack .../16-python3-gi_3.24.1-2build1_amd64.deb ...\n",
            "Unpacking python3-gi (3.24.1-2build1) ...\n",
            "Selecting previously unselected package module-init-tools.\n",
            "Preparing to unpack .../17-module-init-tools_24-1ubuntu2_all.deb ...\n",
            "Unpacking module-init-tools (24-1ubuntu2) ...\n",
            "Selecting previously unselected package python-apt.\n",
            "Preparing to unpack .../18-python-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python-pycurl.\n",
            "Preparing to unpack .../19-python-pycurl_7.43.0-2build2_amd64.deb ...\n",
            "Unpacking python-pycurl (7.43.0-2build2) ...\n",
            "Selecting previously unselected package python-software-properties.\n",
            "Preparing to unpack .../20-python-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package python3-software-properties.\n",
            "Preparing to unpack .../21-python3-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package software-properties-common.\n",
            "Preparing to unpack .../22-software-properties-common_0.96.24.17_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.17) ...\n",
            "Selecting previously unselected package unattended-upgrades.\n",
            "Preparing to unpack .../23-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n",
            "Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n",
            "Setting up python-apt-common (1.4.0~beta3build2) ...\n",
            "Setting up python3-apt (1.4.0~beta3build2) ...\n",
            "Setting up iso-codes (3.75-1) ...\n",
            "Setting up distro-info-data (0.36ubuntu0.2) ...\n",
            "Setting up python-pycurl (7.43.0-2build2) ...\n",
            "Setting up lsb-release (9.20160110ubuntu5) ...\n",
            "Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Setting up libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Setting up unattended-upgrades (0.98ubuntu1.1) ...\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Setting up cron (3.0pl1-128ubuntu5) ...\n",
            "Adding group `crontab' (GID 102) ...\n",
            "Done.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Setting up kmod (24-1ubuntu2) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Setting up python3-gi (3.24.1-2build1) ...\n",
            "Setting up module-init-tools (24-1ubuntu2) ...\n",
            "Setting up python3-software-properties (0.96.24.17) ...\n",
            "Setting up dbus (1.10.22-1ubuntu1) ...\n",
            "Setting up python-apt (1.4.0~beta3build2) ...\n",
            "Setting up python3-dbus (1.2.4-1build3) ...\n",
            "Setting up python-software-properties (0.96.24.17) ...\n",
            "Setting up software-properties-common (0.96.24.17) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Processing triggers for dbus (1.10.22-1ubuntu1) ...\n",
            "gpg: keybox '/tmp/tmpxz4pg4et/pubring.gpg' created\n",
            "gpg: /tmp/tmpxz4pg4et/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 19816 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ERD2Z46TyriN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x_oR8Fw8yrqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "d5f82a43-d5d1-441d-92d5-2939f9ab66d9"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow-gpu\n",
        "!pip install pandas"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.10.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.6.1)\n",
            "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (39.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.31.1)\n",
            "Requirement already satisfied: numpy<=1.14.5,>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: tensorboard<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow) (2.6.11)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow) (0.14.1)\n",
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c3/000755084b5e7b5a11df1b9166a54936075ec280b7a615cecce42973fc8b/tensorflow_gpu-1.10.1-cp36-cp36m-manylinux1_x86_64.whl (253.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 253.3MB 126kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x4f486000 @  0x7f7a39eb31c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: numpy<=1.14.5,>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.14.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.31.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.6.1)\n",
            "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (39.1.0)\n",
            "Requirement already satisfied: tensorboard<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow-gpu) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow-gpu) (2.6.11)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.10.1\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.22.0)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.5)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.14.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nnqec9LQ36-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1637
        },
        "outputId": "5e37904f-39e1-436c-b86b-bc0214da848f"
      },
      "cell_type": "code",
      "source": [
        "# To determine which version you're using:\n",
        "!pip show tensorflow\n",
        "\n",
        "# For the current version: \n",
        "!pip install --upgrade tensorflow2\n",
        "\n",
        "# For a specific version:\n",
        "!pip install tensorflow==1.2\n",
        "\n",
        "# For the latest nightly build:\n",
        "!pip install tf-nightly"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.10.1\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: opensource@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: setuptools, termcolor, protobuf, numpy, six, gast, absl-py, wheel, grpcio, tensorboard, astor\n",
            "Required-by: \n",
            "Collecting tensorflow2\n",
            "\u001b[31m  Could not find a version that satisfies the requirement tensorflow2 (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for tensorflow2\u001b[0m\n",
            "Collecting tensorflow==1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/55/7995cc1e9e60fa37ea90e6777d832e75026fde5c6109215d892aaff2e9b7/tensorflow-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (35.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 35.0MB 499kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (3.6.1)\n",
            "Collecting markdown==2.2.0 (from tensorflow==1.2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/99/288a81a38526a42c98b5b9832c6e339ca8d5dd38b19a53abfac7c8037c7f/Markdown-2.2.0.tar.gz (236kB)\n",
            "\u001b[K    100% |████████████████████████████████| 245kB 21.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.11.0)\n",
            "Collecting backports.weakref==1.0rc1 (from tensorflow==1.2)\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f7/ae34b6818b603e264f26fe7db2bd07850ce331ce2fde74b266d61f4a2d87/backports.weakref-1.0rc1-py3-none-any.whl\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (0.31.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (0.14.1)\n",
            "Collecting html5lib==0.9999999 (from tensorflow==1.2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K    100% |████████████████████████████████| 890kB 9.9MB/s \n",
            "\u001b[?25hCollecting bleach==1.5.0 (from tensorflow==1.2)\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.14.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorflow==1.2) (39.1.0)\n",
            "Building wheels for collected packages: markdown, html5lib\n",
            "  Running setup.py bdist_wheel for markdown ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b6/52/17/f0af18e3e0ec6fa60b361ffed15b4c3468f6f3bcdb87fbe079\n",
            "  Running setup.py bdist_wheel for html5lib ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built markdown html5lib\n",
            "\u001b[31mtensorboard 1.10.0 has requirement markdown>=2.6.8, but you'll have markdown 2.2.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: markdown, backports.weakref, html5lib, bleach, tensorflow\n",
            "  Found existing installation: Markdown 2.6.11\n",
            "    Uninstalling Markdown-2.6.11:\n",
            "      Successfully uninstalled Markdown-2.6.11\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 2.1.4\n",
            "    Uninstalling bleach-2.1.4:\n",
            "      Successfully uninstalled bleach-2.1.4\n",
            "  Found existing installation: tensorflow 1.10.1\n",
            "    Uninstalling tensorflow-1.10.1:\n",
            "      Successfully uninstalled tensorflow-1.10.1\n",
            "Successfully installed backports.weakref-1.0rc1 bleach-1.5.0 html5lib-0.9999999 markdown-2.2.0 tensorflow-1.2.0\n",
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b0/98f2f7ea7d6d01fbf764a547715a5fcfe50a9343dad57bdf4591cca406e0/tf_nightly-1.11.0.dev20180911-cp36-cp36m-manylinux1_x86_64.whl (63.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 63.2MB 362kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.14.5)\n",
            "Collecting keras-applications>=1.0.5 (from tf-nightly)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/9c/6e9393ead970fd97be0cfde912697dafec5800d9191f5ba25352fa537d72/Keras_Applications-1.0.5-py2.py3-none-any.whl (44kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 15.1MB/s \n",
            "\u001b[?25hCollecting tb-nightly<1.12.0a0,>=1.11.0a0 (from tf-nightly)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/a1/0fd6c6a942a319a56db816ed560760f27383494473e88e03fa8a6bc117d1/tb_nightly-1.11.0a20180907-py3-none-any.whl (3.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.4MB 962kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (39.1.0)\n",
            "Collecting keras-preprocessing>=1.0.3 (from tf-nightly)\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/bd/796f986980da4d6adc77ffd8b2b11074e7b17a7b74b03789aefac5709c4b/Keras_Preprocessing-1.0.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.11.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.31.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.5->tf-nightly) (2.8.0)\n",
            "Requirement already satisfied: keras>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.5->tf-nightly) (2.1.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.12.0a0,>=1.11.0a0->tf-nightly) (0.14.1)\n",
            "Collecting markdown>=2.6.8 (from tb-nightly<1.12.0a0,>=1.11.0a0->tf-nightly)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl (78kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 24.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-preprocessing>=1.0.3->tf-nightly) (0.19.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.6->keras-applications>=1.0.5->tf-nightly) (3.13)\n",
            "\u001b[31mtensorflow 1.2.0 has requirement markdown==2.2.0, but you'll have markdown 2.6.11 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, markdown, tb-nightly, keras-preprocessing, tf-nightly\n",
            "  Found existing installation: Markdown 2.2.0\n",
            "    Uninstalling Markdown-2.2.0:\n",
            "      Successfully uninstalled Markdown-2.2.0\n",
            "Successfully installed keras-applications-1.0.5 keras-preprocessing-1.0.3 markdown-2.6.11 tb-nightly-1.11.0a20180907 tf-nightly-1.11.0.dev20180911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lzVI9JGUyrm0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as pl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xqdq3HCkywf-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "4f3dbfcd-4955-4d70-e907-dfa9fc41ebd4"
      },
      "cell_type": "code",
      "source": [
        "#Import datasets & set datasets\n",
        "\n",
        "X_data = list()\n",
        "Y_data = list()\n",
        "def load1(x, y, result):\n",
        "  n_datasets = int(input('Please type the number of datasets : '))\n",
        "  filename = input('Please type the name of files : ')\n",
        "  path = 'drive/datasets/'\n",
        "  for i in range(1, n_datasets):\n",
        "    name = path + filename + '/' + filename + str(i) + '.csv'\n",
        "    file= pd.read_csv(name)\n",
        "    dataset = file.values.tolist()\n",
        "    for row in dataset:\n",
        "      rows =list()\n",
        "      for column in row:\n",
        "        rows.append(column.split())\n",
        "      rowdata = [list(map(int,i)) for i in rows]\n",
        "      x.append(rowdata[0])\n",
        "      y.append(result)\n",
        "          \n",
        "def load2(x, y, result):\n",
        "  n_datasets = int(input('Please type the number of datasets : '))\n",
        "  filename = input('Please type the name of files : ')\n",
        "  path = 'drive/datasets/nobody/'\n",
        "  for i in range(1, n_datasets):\n",
        "      file= pd.read_csv(path + filename + '/' + filename + str(i) + '.csv')\n",
        "      dataset = file.values.tolist()\n",
        "      for row in dataset:\n",
        "        rows =list()\n",
        "        for column in row:\n",
        "          rows.append(column.split())\n",
        "        rowdata = [list(map(int,i)) for i in rows]\n",
        "        x.append(rowdata[0])\n",
        "        y.append(result)\n",
        "\n",
        "n = int(input(\"Please type the number of days: \"))\n",
        "\n",
        "for i in range(n):\n",
        "  load1(X_data, Y_data, [1, 0]) # Exist\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please type the number of days: 5\n",
            "Please type the number of datasets : 181\n",
            "Please type the name of files : labeled_data1_20180814_153212_human\n",
            "Please type the number of datasets : 127\n",
            "Please type the name of files : labeled_data1_20180813_164819_human\n",
            "Please type the number of datasets : 291\n",
            "Please type the name of files : labeled_data1_20180810_125246_human\n",
            "Please type the number of datasets : 156\n",
            "Please type the name of files : labeled_data1_20180810_092138_human\n",
            "Please type the number of datasets : 87\n",
            "Please type the name of files : labeled_data1_20180809_173925_human\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zBDLHSBl7Knm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e5b513b9-f4d3-4f88-f3b1-6143116b5639"
      },
      "cell_type": "code",
      "source": [
        "load2(X_data, Y_data, [0, 1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please type the number of datasets : 59\n",
            "Please type the name of files : labeled_data1_20180814_102745_none\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9M6zegUXllQt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.02\n",
        "total_epoch = 50\n",
        "batch_size = 500\n",
        "\n",
        "n_input = 100\n",
        "n_step = len(X_data)\n",
        "n_hidden = 128\n",
        "n_class = 2\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DSlNmpr972uE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "# Set X, Y as place holder\n",
        "X = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
        "Y = tf.placeholder(tf.float32, [None, n_class])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QGnZTppx72mo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "W = tf.Variable(tf.random_uniform([n_hidden, n_class]))\n",
        "b = tf.Variable(tf.zeros([n_class]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FvuqhC1Hmbzx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
        "#cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
        "#cell = tf.nn.rnn_cell.GRUCell(n_hidden)\n",
        "\n",
        "# To avoid overfitting\n",
        "cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=0.5)\n",
        "\n",
        "#cell2 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
        "\n",
        "# Make combination of cells \n",
        "#multi_cell = tf.nn.rnn_cell.MultiRNNCell([cell, cell2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uB5uQC8C72am",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make  Deep RNN\n",
        "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
        "\n",
        "# Final output layers\n",
        "outputs = tf.transpose(outputs, [1, 0, 2])\n",
        "outputs = outputs[-1]\n",
        "\n",
        "model = tf.matmul(outputs, W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wpFb9kc48xpm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cross-Entropy_v2\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3bRutAcw8-F_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "outputId": "c4c8c152-6bb3-4239-94a2-822b51fd9525"
      },
      "cell_type": "code",
      "source": [
        "# Training \n",
        "sess = tf.Session()\n",
        "saver = tf.train.Saver(tf.global_variables())\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "# make input and target to train\n",
        "batch_xs = np.reshape(X_data, (-1, n_step, n_input))\n",
        "batch_ys = Y_data\n",
        "\n",
        "for epoch in range(total_epoch):\n",
        "  _, loss =  sess.run([optimizer, cost], \n",
        "                      feed_dict={X: batch_xs, Y: batch_ys})\n",
        "  \n",
        "  buff = list()\n",
        "  buff.append(format(loss))\n",
        "  \n",
        " \n",
        "    \n",
        "  print('Epoch:', '%04d' % (epoch + 1),\n",
        "       'Avg. cost =', '{:.3f}'.format(loss))\n",
        "  \n",
        "print('최적화 완료!')\n",
        "\n",
        "saver.save(sess, 'drive/model/rnn', total_epoch)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 Avg. cost = 0.704\n",
            "Epoch: 0002 Avg. cost = 0.769\n",
            "Epoch: 0003 Avg. cost = 3.620\n",
            "Epoch: 0004 Avg. cost = 0.745\n",
            "Epoch: 0005 Avg. cost = 1.098\n",
            "Epoch: 0006 Avg. cost = 2.017\n",
            "Epoch: 0007 Avg. cost = 0.996\n",
            "Epoch: 0008 Avg. cost = 1.114\n",
            "Epoch: 0009 Avg. cost = 2.011\n",
            "Epoch: 0010 Avg. cost = 4.478\n",
            "Epoch: 0011 Avg. cost = 3.823\n",
            "Epoch: 0012 Avg. cost = 3.691\n",
            "Epoch: 0013 Avg. cost = 4.018\n",
            "Epoch: 0014 Avg. cost = 2.486\n",
            "Epoch: 0015 Avg. cost = 3.392\n",
            "Epoch: 0016 Avg. cost = 1.589\n",
            "Epoch: 0017 Avg. cost = 0.690\n",
            "Epoch: 0018 Avg. cost = 1.765\n",
            "Epoch: 0019 Avg. cost = 0.698\n",
            "Epoch: 0020 Avg. cost = 2.526\n",
            "Epoch: 0021 Avg. cost = 5.474\n",
            "Epoch: 0022 Avg. cost = 1.286\n",
            "Epoch: 0023 Avg. cost = 2.865\n",
            "Epoch: 0024 Avg. cost = 0.782\n",
            "Epoch: 0025 Avg. cost = 0.694\n",
            "Epoch: 0026 Avg. cost = 2.525\n",
            "Epoch: 0027 Avg. cost = 2.217\n",
            "Epoch: 0028 Avg. cost = 0.715\n",
            "Epoch: 0029 Avg. cost = 4.812\n",
            "Epoch: 0030 Avg. cost = 3.390\n",
            "Epoch: 0031 Avg. cost = 2.104\n",
            "Epoch: 0032 Avg. cost = 0.827\n",
            "Epoch: 0033 Avg. cost = 0.984\n",
            "Epoch: 0034 Avg. cost = 2.095\n",
            "Epoch: 0035 Avg. cost = 0.689\n",
            "Epoch: 0036 Avg. cost = 5.646\n",
            "Epoch: 0037 Avg. cost = 1.500\n",
            "Epoch: 0038 Avg. cost = 1.296\n",
            "Epoch: 0039 Avg. cost = 2.239\n",
            "Epoch: 0040 Avg. cost = 1.050\n",
            "Epoch: 0041 Avg. cost = 4.224\n",
            "Epoch: 0042 Avg. cost = 1.135\n",
            "Epoch: 0043 Avg. cost = 3.928\n",
            "Epoch: 0044 Avg. cost = 0.750\n",
            "Epoch: 0045 Avg. cost = 1.419\n",
            "Epoch: 0046 Avg. cost = 0.787\n",
            "Epoch: 0047 Avg. cost = 1.309\n",
            "Epoch: 0048 Avg. cost = 0.703\n",
            "Epoch: 0049 Avg. cost = 3.160\n",
            "Epoch: 0050 Avg. cost = 1.592\n",
            "최적화 완료!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/model/rnn-50'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "y9QiooKI35JO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "ae0b2b37-b98d-4545-a586-b6531666e957"
      },
      "cell_type": "code",
      "source": [
        "# Print the Accuracy\n",
        "\n",
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print(buff)\n",
        "pl.plot(buff)\n",
        "\n",
        "#test_batch_size = len(X_data)\n",
        "#test_xs = np.reshape(X_data, (-1, n_step, n_input))\n",
        "#test_ys = Y_data\n",
        "\n",
        "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: batch_xs, Y: batch_ys}))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1.5922071933746338']\n",
            "정확도: 44.88\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAFKCAYAAADlia4RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc8aab4f898>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}
